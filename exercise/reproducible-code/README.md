# Reproducible Code Exercise

Practice implementing key principles for reproducible research code by fixing a small simulation project. This assignment is designed to be completed with an issue based git workflow.

## Learning Objectives

Learn how to structure a small project so that it is reproducible, deterministic, and easy to rerun. In particular, you will practice config as data, stable paths, and named arguments. You will also practice creating issues, working on branches, writing descriptive commits, and merging pull requests.

## Project Structure

```
reproducible-code/
├── config/
│   └── simulation.json      # Parameters for the simulation
├── input/                   # Raw inputs (unused in this toy project)
├── output/                  # Generated outputs (stable paths)
│   └── simulation.json      # <- Generated by scripts/run_simulation.py
├── src/
│   ├── __init__.py
│   └── reproducible.py      # <- Implement functions here
├── scripts/
│   └── run_simulation.py    # <- Fix this script to follow principles
├── tests/
│   ├── __init__.py
│   ├── test_reproducible_tasks.py
│   └── test_workflow.py
├── pyproject.toml
└── README.md
```

## Setup

Accept this assignment on GitHub Classroom and clone your repository.

## Exercise Steps

Create an issue on GitHub titled `Make simulation reproducible`. Create a branch from the issue and check it out locally.

Read `docs/workflow/reproducible_code.md` in the Economics repository and use it as a reference. Then fix `scripts/run_simulation.py` and implement any missing functions in `src/reproducible.py` so that the project follows the principles and the tests pass.

Run tests locally:

```bash
uv run pytest -v
```

Commit your changes with descriptive messages that reference the issue number, for example `Make simulation reproducible, closes #1`. Push your branch, open a pull request, and merge it.

## Grading Criteria

Your submission is graded on two components.

Reproducible code requirements are graded by `tests/test_reproducible_tasks.py`. Git workflow is graded by `tests/test_workflow.py` and by the presence of a closed issue and a merged pull request on GitHub.

## Verification

Verify that all tests pass locally using `uv run pytest -v`, then verify that GitHub Actions passes on your pull request.

